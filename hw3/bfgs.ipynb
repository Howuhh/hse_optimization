{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "from oracle import make_oracle\n",
    "from step_search import wolfe_line_search\n",
    "from optimize import optimize_newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFGS!\n",
    "def bfgs_update(H, I, s, y):\n",
    "    p = 1 / (y.T @ s)\n",
    "    V = I - p * np.outer(y, s)\n",
    "    \n",
    "    H_new = V.T @ H @ V + p * np.outer(s, s)\n",
    "    \n",
    "    return H_new\n",
    "\n",
    "def bfgs(oracle, w, tol=1e-8, gamma=30, max_iter=10000, verbose=False):\n",
    "    I = np.identity(oracle.dim)\n",
    "    H = gamma * I\n",
    "    \n",
    "    prev_w, prev_grad = w, oracle.grad(w).reshape(-1, 1)\n",
    "    for iter_ in range(max_iter):\n",
    "        if prev_grad.T @ prev_grad <= tol:\n",
    "            break\n",
    "        \n",
    "        direction = H @ prev_grad\n",
    "        alpha = wolfe_line_search(oracle, w, direction)\n",
    "        \n",
    "        if iter_ == 0:\n",
    "            alpha = 1.0\n",
    "\n",
    "        w = w - alpha * direction\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Iteration {iter_}: {oracle.value(w)}, alpha: {alpha}\")\n",
    "        \n",
    "        new_grad = oracle.grad(w).reshape(-1, 1)\n",
    "                \n",
    "        s = w - prev_w\n",
    "        y = new_grad - prev_grad\n",
    "        \n",
    "        if iter_ == 0:\n",
    "            H = ((y.T @ s) / (y.T @ y)) * H\n",
    "        \n",
    "        H = bfgs_update(H, I, s, y)        \n",
    "        prev_w, prev_grad = w, new_grad\n",
    "\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = make_oracle(\"data/a1a.txt\")\n",
    "w_init = np.zeros((oracle.dim, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: 6.799790183977318, alpha: 1.0\n",
      "Iteration 1: 3.155299174894922, alpha: [[0.50000655]]\n",
      "Iteration 2: 2.3505144133758664, alpha: 1.0\n",
      "Iteration 3: 2.071314449921163, alpha: [[0.49962633]]\n",
      "Iteration 4: 1.966200565086752, alpha: 1.0\n",
      "Iteration 5: 1.4379936797961366, alpha: 1.0\n",
      "Iteration 6: 1.0651342962372563, alpha: 1.0\n",
      "Iteration 7: 0.9978287153805063, alpha: 1.0\n",
      "Iteration 8: 0.7711179108123621, alpha: [[0.49970057]]\n",
      "Iteration 9: 0.6906229594605998, alpha: [[0.49924556]]\n",
      "Iteration 10: 0.6132023475534327, alpha: [[0.49952347]]\n",
      "Iteration 11: 0.5695093935307574, alpha: 1.0\n",
      "Iteration 12: 0.49650466649296454, alpha: [[0.49851075]]\n",
      "Iteration 13: 0.4807835243528352, alpha: [[0.49900374]]\n",
      "Iteration 14: 0.45029390905580396, alpha: [[0.21079889]]\n",
      "Iteration 15: 0.4365371493742264, alpha: [[0.49902375]]\n",
      "Iteration 16: 0.4122754986840929, alpha: [[0.21051086]]\n",
      "Iteration 17: 0.3975260759125425, alpha: [[0.21075402]]\n",
      "Iteration 18: 0.38838415284012656, alpha: [[0.2110458]]\n",
      "Iteration 19: 0.3858415400611038, alpha: [[0.49950883]]\n",
      "Iteration 20: 0.3781098959161658, alpha: [[0.49984709]]\n",
      "Iteration 21: 0.3698948000607634, alpha: [[0.49990328]]\n",
      "Iteration 22: 0.36085091102996725, alpha: [[0.21118622]]\n",
      "Iteration 23: 0.3499301517281533, alpha: [[0.49986253]]\n",
      "Iteration 24: 0.3360014579882614, alpha: [[0.21103267]]\n",
      "Iteration 25: 0.32598598112275706, alpha: [[0.2110008]]\n",
      "Iteration 26: 0.3183149175712645, alpha: [[0.49966152]]\n",
      "Iteration 27: 0.31600328287961627, alpha: [[0.49903739]]\n",
      "Iteration 28: 0.31107884308624706, alpha: [[0.49971519]]\n",
      "Iteration 29: 0.30809341618224495, alpha: [[0.4995399]]\n",
      "Iteration 30: 0.30506719111757336, alpha: [[0.49974363]]\n",
      "Iteration 31: 0.30286328501778476, alpha: [[0.49967117]]\n",
      "Iteration 32: 0.30118211352028085, alpha: [[0.49956303]]\n",
      "Iteration 33: 0.2998828673605085, alpha: [[0.49959574]]\n",
      "Iteration 34: 0.2994448899423116, alpha: [[0.21107636]]\n",
      "Iteration 35: 0.29936164725506553, alpha: [[0.49927545]]\n",
      "Iteration 36: 0.29919765516958097, alpha: [[0.49958921]]\n",
      "Iteration 37: 0.2990304077642875, alpha: [[0.49993248]]\n",
      "Iteration 38: 0.29896256427039336, alpha: [[0.49979747]]\n",
      "Iteration 39: 0.2989174051377366, alpha: 1.0\n",
      "Iteration 40: 0.29884294517577326, alpha: [[0.49984471]]\n",
      "Iteration 41: 0.2987577665899509, alpha: [[0.49988228]]\n",
      "Iteration 42: 0.2987045749005882, alpha: [[0.49975891]]\n",
      "Iteration 43: 0.2986765878450135, alpha: [[0.49984003]]\n",
      "Iteration 44: 0.2986573314256441, alpha: [[0.4998109]]\n",
      "Iteration 45: 0.29864072333352415, alpha: [[0.49989229]]\n",
      "Iteration 46: 0.29863034239666597, alpha: 1.0\n",
      "Iteration 47: 0.29859276171748833, alpha: 1.0\n",
      "Iteration 48: 0.2985542902624319, alpha: 1.0\n",
      "Iteration 49: 0.29850617754623526, alpha: [[0.5000436]]\n",
      "Iteration 50: 0.29845304534401446, alpha: [[0.50002584]]\n",
      "Iteration 51: 0.298381730728666, alpha: 1.2060113333333333\n",
      "Iteration 52: 0.29831705459111724, alpha: [[0.50003858]]\n",
      "Iteration 53: 0.2982476153023108, alpha: 1.2060113333333333\n",
      "Iteration 54: 0.2981795102641121, alpha: [[0.50002998]]\n",
      "Iteration 55: 0.2981423629994326, alpha: 1.2060113333333333\n",
      "Iteration 56: 0.2980656793385758, alpha: 1.0\n",
      "Iteration 57: 0.29804562123942324, alpha: 0.6030056666666667\n",
      "Iteration 58: 0.29802308332926664, alpha: 1.2060113333333333\n",
      "Iteration 59: 0.29801327599408994, alpha: 1.2060113333333333\n",
      "Iteration 60: 0.29799866794845103, alpha: 1.0\n",
      "Iteration 61: 0.2979885427497102, alpha: 1.0\n",
      "Iteration 62: 0.2979750462373109, alpha: 1.0\n",
      "Iteration 63: 0.2979656469372461, alpha: 1.2060113333333333\n",
      "Iteration 64: 0.29796338442265047, alpha: 1.0\n",
      "Iteration 65: 0.29796089695627387, alpha: 1.2060113333333333\n",
      "Iteration 66: 0.2979588623083421, alpha: 1.0\n",
      "Iteration 67: 0.2979552887887324, alpha: 1.2060113333333333\n",
      "Iteration 68: 0.29795066419603283, alpha: 1.8174202304696003\n",
      "Iteration 69: 0.2979459097191956, alpha: 1.2060113333333333\n",
      "Iteration 70: 0.29793869845139603, alpha: 1.2060113333333333\n",
      "Iteration 71: 0.29792421355733795, alpha: 1.95725555491397\n",
      "Iteration 72: 0.29791084966688486, alpha: 1.2060113333333333\n",
      "Iteration 73: 0.2979031714602538, alpha: 1.2060113333333333\n",
      "Iteration 74: 0.2978983681993506, alpha: 1.84453558496725\n",
      "Iteration 75: 0.29789250892167723, alpha: 1.2060113333333333\n",
      "Iteration 76: 0.29788943272152796, alpha: 1.2060113333333333\n",
      "CPU times: user 598 ms, sys: 68.1 ms, total: 666 ms\n",
      "Wall time: 487 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.51538753e+00],\n",
       "       [-7.64074136e-01],\n",
       "       [-2.35044698e-01],\n",
       "       [ 4.46205571e-01],\n",
       "       [ 1.99601032e-01],\n",
       "       [-1.05342165e-01],\n",
       "       [-4.96974055e-01],\n",
       "       [-7.16873072e-02],\n",
       "       [ 6.49719345e-01],\n",
       "       [ 1.84028670e-01],\n",
       "       [-6.99898393e-01],\n",
       "       [ 0.00000000e+00],\n",
       "       [-1.97934280e-01],\n",
       "       [-6.02854672e-01],\n",
       "       [-2.68250184e-01],\n",
       "       [-3.51926688e-01],\n",
       "       [-8.58954258e-02],\n",
       "       [-5.59772786e-01],\n",
       "       [-7.67354344e-01],\n",
       "       [ 2.55262676e-01],\n",
       "       [ 4.68483815e+00],\n",
       "       [ 2.22771359e-01],\n",
       "       [ 1.12169257e+00],\n",
       "       [-3.72158734e-01],\n",
       "       [ 8.33748671e-01],\n",
       "       [-6.13120372e+00],\n",
       "       [ 4.67376495e+00],\n",
       "       [-2.60052548e+00],\n",
       "       [-2.26330765e-01],\n",
       "       [-1.33002890e+00],\n",
       "       [ 3.84621984e+00],\n",
       "       [ 2.06321932e+00],\n",
       "       [-6.90031931e+00],\n",
       "       [-1.24229606e+00],\n",
       "       [-4.99955052e+00],\n",
       "       [ 2.22771359e-01],\n",
       "       [ 2.55262676e-01],\n",
       "       [ 4.61589937e-01],\n",
       "       [ 2.19122679e+00],\n",
       "       [-2.10545637e+00],\n",
       "       [ 6.59764815e-01],\n",
       "       [ 4.79587259e-01],\n",
       "       [ 9.64986273e-01],\n",
       "       [-9.09544136e-02],\n",
       "       [-3.06877157e-02],\n",
       "       [-1.74593961e+00],\n",
       "       [ 1.24554144e+00],\n",
       "       [ 5.60024830e-01],\n",
       "       [-2.52073757e-01],\n",
       "       [ 8.61653692e-01],\n",
       "       [ 1.98290198e+00],\n",
       "       [ 9.39112029e-01],\n",
       "       [ 1.24493056e+00],\n",
       "       [ 9.02667255e-01],\n",
       "       [ 1.02472963e+00],\n",
       "       [ 8.27634161e-01],\n",
       "       [ 4.05079355e-01],\n",
       "       [-1.11479084e+01],\n",
       "       [ 8.65553328e-01],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 5.66664546e+00],\n",
       "       [-4.40496448e-01],\n",
       "       [ 5.13958758e+00],\n",
       "       [ 8.21730651e-02],\n",
       "       [-1.22261256e+01],\n",
       "       [-9.04838137e-02],\n",
       "       [ 1.56252243e+00],\n",
       "       [ 1.66311378e+00],\n",
       "       [-8.41661115e+00],\n",
       "       [ 1.69509732e+00],\n",
       "       [ 1.62717785e+00],\n",
       "       [-1.04123039e+00],\n",
       "       [-8.27469371e-01],\n",
       "       [-1.86999786e+00],\n",
       "       [ 1.29810847e-03],\n",
       "       [-1.51187709e+00],\n",
       "       [-3.56822663e-01],\n",
       "       [-1.30663018e+00],\n",
       "       [ 5.04936707e-02],\n",
       "       [-5.46073141e-01],\n",
       "       [-9.59072539e-03],\n",
       "       [-5.68993789e-02],\n",
       "       [ 3.36526147e-01],\n",
       "       [ 8.40115093e+00],\n",
       "       [-1.07179388e+00],\n",
       "       [-8.59700229e+00],\n",
       "       [ 1.07705008e+00],\n",
       "       [-1.60381725e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [-9.80967894e-01],\n",
       "       [ 1.40209110e+01],\n",
       "       [ 9.26697087e+00],\n",
       "       [ 1.66897435e+00],\n",
       "       [-6.96732189e+00],\n",
       "       [ 8.02907869e-01],\n",
       "       [ 0.00000000e+00],\n",
       "       [-1.33690539e-01],\n",
       "       [ 9.89379337e+00],\n",
       "       [ 2.75255277e+00],\n",
       "       [ 1.08608826e+00],\n",
       "       [-5.85525106e+00],\n",
       "       [-6.98894142e+00],\n",
       "       [ 8.42276286e-01],\n",
       "       [ 6.60434389e+00],\n",
       "       [-9.64925722e+00],\n",
       "       [-4.04619475e+00],\n",
       "       [-8.64803299e+00],\n",
       "       [-1.39664150e-01],\n",
       "       [ 7.83846329e-02],\n",
       "       [ 2.50344159e-01],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 4.52911304e+00],\n",
       "       [-9.64698158e+00],\n",
       "       [-7.03799394e+00],\n",
       "       [-1.34117054e-01],\n",
       "       [ 0.00000000e+00],\n",
       "       [-3.74410221e+00],\n",
       "       [ 2.30550356e+01],\n",
       "       [-9.57384487e+00],\n",
       "       [-1.86869976e+00]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bfgs(oracle, w_init, tol=1e-8, verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbfgs_direction(grad, H0, s_q, y_q, r_q):\n",
    "    alpha = np.zeros(len(s_q))\n",
    "    \n",
    "    q = grad\n",
    "    for i in range(len(s_q) - 1, -1, -1):\n",
    "        alpha[i] = r_q[i] * s_q[i].T @ q\n",
    "        q = q - alpha[i] * y_q[i]\n",
    "        \n",
    "    Hd = H0 @ q\n",
    "    for i in range(len(s_q)):\n",
    "        beta = r_q[i] * y_q[i].T @ Hd\n",
    "        Hd = Hd + s_q[i] @ (alpha[i] - beta)    \n",
    "    \n",
    "    return Hd\n",
    "\n",
    "def lbfgs(oracle, w, tol=1e-8, buffer_size=5, gamma=1.0, max_iter=10000, verbose=False):\n",
    "    s_q, y_q, r_q = [deque(maxlen=buffer_size) for _ in range(3)]\n",
    "    I = np.identity(oracle.dim)\n",
    "    \n",
    "    prev_w, prev_grad = w, oracle.grad(w).reshape(-1, 1)\n",
    "    for iter_ in range(max_iter):\n",
    "        if prev_grad.T @ prev_grad <= tol:\n",
    "            break\n",
    "        \n",
    "        if iter_ == 0:\n",
    "            H0 = gamma * I\n",
    "        else:\n",
    "            H0 = (y_q[-1].T @ s_q[-1]) / (y_q[-1].T @ y_q[-1]) * I\n",
    "    \n",
    "        direction = lbfgs_direction(prev_grad, H0, s_q, y_q, r_q)\n",
    "        alpha = wolfe_line_search(oracle, w, direction)\n",
    "        \n",
    "        w = w - alpha * direction\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Iteration {iter_}: {oracle.value(w)}, alpha: {alpha}\")\n",
    "             \n",
    "        new_grad = oracle.grad(w).reshape(-1, 1)\n",
    "        \n",
    "        s_q.append(w - prev_w)\n",
    "        y_q.append(new_grad - prev_grad)\n",
    "        r_q.append(1 / (y_q[-1].T @ s_q[-1]))\n",
    "        \n",
    "        prev_w, prev_grad = w, new_grad\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 620 ms, sys: 54.1 ms, total: 674 ms\n",
      "Wall time: 355 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = lbfgs(oracle, w_init, buffer_size=100, gamma=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
